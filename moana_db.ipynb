{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moana Database Creation\n",
    "Creates and database and loads Moana Project Mangōpare temperature sensor data into the new database.  This is a very simple sqlite database with only bare minimum measurement data and almost no metadata.  This could (and hopefully will) be easily expanded to multiple tables with appropriate (and necessary) metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy.engine import create_engine\n",
    "from sqlalchemy.engine.base import Engine\n",
    "from pandas.io import sql\n",
    "import glob2 as glob\n",
    "import validators\n",
    "from siphon.catalog import TDSCatalog\n",
    "import datetime as datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaData.__init__() got an unexpected keyword argument 'bind'\n",
      "Connection info needed in SQLAlchemy format, example:\n",
      "               postgresql://username:password@hostname/dbname\n",
      "               or an existing connection: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "%sql sqlite:///moana.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a table with measurement keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables created successfully.\n"
     ]
    }
   ],
   "source": [
    "sql_statements = [ \n",
    "    \"\"\"CREATE TABLE IF NOT EXISTS obs (\n",
    "            tid INTEGER PRIMARY KEY, \n",
    "            file STR,\n",
    "            date DATE, \n",
    "            time TIME,\n",
    "            lat FLOAT NOT NULL,\n",
    "            lon FLOAT NOT NULL,\n",
    "            temp FLOAT NOT NULL, \n",
    "            qcflag INT NOT NULL\n",
    "        );\"\"\",\n",
    "]\n",
    "\n",
    "# create a database connection\n",
    "try:\n",
    "    with sqlite3.connect('moana.db') as conn:\n",
    "        # create a cursor\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # execute statements\n",
    "        for statement in sql_statements:\n",
    "            cursor.execute(statement)\n",
    "\n",
    "        # commit the changes\n",
    "        conn.commit()\n",
    "\n",
    "        print(\"Tables created successfully.\")\n",
    "except sqlite3.OperationalError as e:\n",
    "    print(\"Failed to create tables:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods open the netcdf files from the Mangōpare THREDDS server and insert files into the new database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_insert(filename:str, disk_engine: Engine, cat):\n",
    "    # load file and format columns\n",
    "    try:\n",
    "        ds = cat.datasets[filename].remote_access(use_xarray=True)\n",
    "    except:\n",
    "        ds = xr.open_dataset(filename)\n",
    "    df = ds.to_dataframe().drop_duplicates().reset_index().drop(columns=['DEPTH_QC','TEMP_QC','POSITION_QC','TIME_QC','PRESSURE','PRESSURE_QC']).dropna()\n",
    "    ds.close()\n",
    "    df = df.rename(columns={\"TIME\":\"time\", \"LATITUDE\":\"lat\", \"LONGITUDE\":\"lon\", \"TEMP\":\"temp\", \"DEPTH\":\"depth\", \"QC_FLAG\":\"qcflag\"})\n",
    "    #df['time'] = df['time'].dt.tz_localize('UTC')\n",
    "    df['file'] = filename\n",
    "    # insert into sql database\n",
    "    df.to_sql('observations', disk_engine, if_exists='append')\n",
    "    return disk_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_moana(\n",
    "        start_date: np.datetime64,\n",
    "        end_date: np.datetime64,\n",
    "        disk_engine: Engine = create_engine('sqlite:///moana.db'),\n",
    "        source: str = \"http://thredds.moanaproject.org:6443/thredds/catalog/moana/Mangopare/public/catalog.html\"\n",
    "):\n",
    "    \"\"\"Loads public Mangōpare data from the Moana Project THREDDS server,\n",
    "    or local directory, between start_date and end_date.  Inserts data\n",
    "    into sqlite database\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source : str, optional\n",
    "        THREDDS server url, by default \"http://thredds.moanaproject.org:6443/thredds/catalog/moana/Mangopare/public/catalog.html\"\n",
    "        or directory to find files in, e.g., '/path_to_files/*.nc'\n",
    "    start_date : np.datetime64, optional\n",
    "        Start of desired date range, by default start_date\n",
    "    end_date : np.datetime64, optional\n",
    "        End of desired date range, by default end_date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Updated database\n",
    "    \"\"\"\n",
    "\n",
    "    if validators.url(source):\n",
    "    # load THREDDS catalog\n",
    "        cat = TDSCatalog(source)\n",
    "        filelist = sorted(cat.datasets)\n",
    "    else:\n",
    "        filelist = glob.glob(source)\n",
    "\n",
    "    ingested_files = []\n",
    "    failed_files = []\n",
    "\n",
    "    for file in filelist:\n",
    "        try:\n",
    "            sdn = pd.to_datetime(file[6:14], format=\"%Y%m%d\").to_numpy()\n",
    "            if (sdn < start_date) or (sdn > end_date):\n",
    "                continue\n",
    "            disk_engine = data_insert(filename = file, disk_engine = disk_engine, cat = cat)\n",
    "            ingested_files.append(file)\n",
    "        except Exception as e:\n",
    "            failed_files.append(file)\n",
    "            print(e)\n",
    "            continue\n",
    "    return disk_engine, ingested_files, failed_files\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose a start and date date of the data we'd like to include connect to the database, and insert the data from the THREDDS server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = np.datetime64(\"2024-12-19\")\n",
    "end_date = np.datetime64(\"2024-12-31\")\n",
    "disk_engine = create_engine('sqlite:///moana.db')\n",
    "disk_engine, ig, ff = load_moana(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, double check the first and last deployment datetime by querying the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_engine = create_engine('sqlite:////Users/jkat/source/moana-plots/moana.db')\n",
    "qc_flag_max = 3\n",
    "moana_df = pd.read_sql_query('SELECT MIN(time) as atime, AVG(lat) as alat, AVG(lon) as alon FROM observations WHERE qcflag<'+str(qc_flag_max)+' GROUP BY file', disk_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maxt</th>\n",
       "      <th>mint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-30 20:59:29.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         maxt  mint\n",
       "0  2024-12-30 20:59:29.000000     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query(\n",
    "    \"SELECT MAX(time) as maxt, MIN(time) as mint FROM observations\",\n",
    "    disk_engine,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plots_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
